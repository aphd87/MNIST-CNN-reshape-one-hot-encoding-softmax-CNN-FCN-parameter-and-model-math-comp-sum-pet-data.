{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Recap-\n",
        "1. Convolutional Neural Network- Feature Extraction, Dim Reduction\n",
        "2. Layers- \n",
        "1. Convolution Layer - Kernel Matrix\n",
        "2. Maxpooling layer- subsampling\n",
        "3. Activation layer- Relu\n",
        "4. FCN"
      ],
      "metadata": {
        "id": "Oa4YVekD9A6Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "XrCZCJsJyhdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Directory Structure\n",
        "Dataset- 1.Train Set\n",
        "            1.1Dog- Images\n",
        "            1.2Cat\n",
        "            1.3 Tiger\n",
        "        -Test Set \n",
        "            Dog\n",
        "            Cat\n",
        "            Tiger"
      ],
      "metadata": {
        "id": "rqF8dpC5ZGji"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BqqEQxW5ZBUt"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRAtU6o5aq47",
        "outputId": "96cde501-3f88-44d0-feeb-646857ceed6d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Library\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense\n",
        "\n",
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test,y_test)=mnist.load_data()"
      ],
      "metadata": {
        "id": "RbA9QAIGbCTZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating an image plot\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(X_train[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "7Dk97pPC0Kid",
        "outputId": "18d165a7-641a-41fc-9dc0-d26d056d5a33"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f605c41acd0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOx0lEQVR4nO3df5DU9X3H8deb6wmI4EAMhBBSonKhxDQQLxgbE0ycOGBnis40JkzHEGLnMpNoMdo2ju1MnHSmQzMmNmkwKYlEzA+czKiR6VAjXplaE0M4kAiCBkOggidUsAV/4R337h/3NXPqfT+77H53v3v3fj5mbnb3+97vft+z+uK73+9nv/sxdxeA0W9M2Q0AaA7CDgRB2IEgCDsQBGEHgviDZm7sNBvr4zShmZsEQnlFL+pVP2HD1eoKu5ktkvQNSW2SvufuK1PPH6cJusAuqWeTABI2e3dureaP8WbWJmmVpMWS5kpaamZza309AI1VzzH7AklPufted39V0l2SlhTTFoCi1RP2GZKeHvL4QLbsdcysy8x6zKynTyfq2ByAejT8bLy7r3b3TnfvbNfYRm8OQI56wn5Q0swhj9+RLQPQguoJ+xZJs83sXWZ2mqRPSVpfTFsAilbz0Ju795vZNZJ+psGhtzXu/nhhnQEoVF3j7O6+QdKGgnoB0EB8XRYIgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIJo6ZTNGn/6PnZ+s934+f8qvX1+4Nrnu+x5Zlqy/fdVpyXrbpm3JejTs2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZkTSwcH6y/s0130rWz23P/19soMK2H73w+8n6k50nk/W/mfXBCluIpa6wm9k+ScclnZTU7+6dRTQFoHhF7Nk/6u7PFfA6ABqIY3YgiHrD7pIeMLOtZtY13BPMrMvMesysp0/535MG0Fj1foy/yN0PmtlUSRvN7Al3f2joE9x9taTVkjTJpnid2wNQo7r27O5+MLs9LOleSQuKaApA8WoOu5lNMLOJr92XdKmknUU1BqBY9XyMnybpXjN77XV+7O73F9IVmqbv0vRo6d/e9oNkvaM9fU35QGI0fW9fX3Ld/xsYm6zPT5d1YvEHcmvjN+1IrjvwyivpFx+Bag67u++V9L4CewHQQAy9AUEQdiAIwg4EQdiBIAg7EASXuI4CbZMm5dZe/Mic5LpfvPXHyfpHx79QYeu17y/ueP5PkvXu2y5M1n9+8zeT9Y3f+05ube4Pr0mue/aXHknWRyL27EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBOPso8CBO2fk1rZ8YFUTOzk1X5m6JVm//4z0OPzyfZcm62tnPZhbmzT3SHLd0Yg9OxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwTj7CND/sfOT9XXz8qdNHqP0Tz1Xsnz/Jcl6z4N/lKzvuDq/t00vj0uuO7Xn5WT9qefT1+q3/+Om3NoYS646KrFnB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgzN2btrFJNsUvsPS4bUQDC+cn6/+89rZk/dz22r8u8WdPXJGst/35i8n60T99d7J+5Lz8Ae2OVU8n1+1/+kCyXsm/HdyaW+s9mR7D/+yyv0rW2zZtq6mnRtvs3TrmR4d90yvu2c1sjZkdNrOdQ5ZNMbONZrYnu51cZMMAilfNx/g7JC16w7IbJXW7+2xJ3dljAC2sYtjd/SFJR9+weImktdn9tZIuL7gvAAWr9WBvmrv3ZveflTQt74lm1iWpS5LG6fQaNwegXnWfjffBM3y5Z/ncfbW7d7p7Z7vG1rs5ADWqNeyHzGy6JGW3h4trCUAj1Br29ZKWZfeXSbqvmHYANErFY3YzWyfpYklnmdkBSV+WtFLST8zsakn7JV3ZyCZHOjv/Pcn6c9enx3w72tPXpG89kV/7jxfmJtc9ctfMZP0tz6fnKT/zh79M1xO1/uSajTWtLX1IeeS6l5L1qfmXyresimF396U5Jb4dA4wgfF0WCIKwA0EQdiAIwg4EQdiBIPgp6QKMOT39NeD+rx5L1n85555k/Xf9rybr1990Q25t8n/9d3LdqRPS34c6mayOXgum70/W9zWnjUKxZweCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIBhnL8DLC9OXsP5sTvqnoCv5yxVfTNYn/jT/MtMyLyNFa2HPDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBMM5egD/+h+3J+pgK/6Yu35/+od7xP/3VKfcEqd3acmt9FWYqb7PmTWXeLOzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIxtmr9L9XXZhb+/tptyTXHVCFKZcfSE+r/E79IlnH8Po8/1fvBzSQXPf+3en/JrO1raaeylRxz25ma8zssJntHLLsZjM7aGbbs7/LGtsmgHpV8zH+DkmLhll+q7vPy/42FNsWgKJVDLu7PyTpaBN6AdBA9Zygu8bMHss+5k/Oe5KZdZlZj5n19OlEHZsDUI9aw/5tSedImiepV9LX8p7o7qvdvdPdO9s1tsbNAahXTWF390PuftLdByR9V9KCYtsCULSawm5m04c8vELSzrznAmgNFcfZzWydpIslnWVmByR9WdLFZjZPkmtwqurPNbDHltA/Pr925pj0OPojr6QPX86+85n0tpPV0avSvPdP3HJehVfYmlv5i72Lk2vOWfG7ZH0kzltfMezuvnSYxbc3oBcADcTXZYEgCDsQBGEHgiDsQBCEHQiCS1yb4MjJM5L1/r37mtNIi6k0tPbkyvcm608s+Vay/u8vnZlbe2bVucl1Jz6fPw32SMWeHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCYJy9Cf76559I1jsSl2KOdAML5+fWDl//cnLd3Z3pcfRLdnwyWZ+waG9ubaJG3zh6JezZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIxtmrZfmlMRX+zfzGReuS9VXqqKWjlrD/K/lTWUvS3Z/+em6toz39E9zv/9WyZP3tV+xK1vF67NmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjG2avl+aUBDSRXXTj+SLJ+3R3nJ+vnfD/9+u3PHs+tHVr41uS6Uz55IFm/9p3dyfri09PX4q9/cVpu7dM7FiXXPetfJyTrODUV9+xmNtPMNpnZLjN73MxWZMunmNlGM9uT3U5ufLsAalXNx/h+STe4+1xJH5T0BTObK+lGSd3uPltSd/YYQIuqGHZ373X3bdn945J2S5ohaYmktdnT1kq6vFFNAqjfKR2zm9ksSfMlbZY0zd17s9KzkoY9ODOzLkldkjRO6bm9ADRO1WfjzewMSXdLus7djw2tubsr5xSWu692905372zX2LqaBVC7qsJuZu0aDPqP3P2ebPEhM5ue1adLOtyYFgEUoeLHeDMzSbdL2u3uQ69XXC9pmaSV2e19DelwFBhn6bd598e/k6w//OFxyfqeE2/LrS0/c19y3XqteObDyfr9v5iXW5u9It7POZepmmP2D0m6StIOM9ueLbtJgyH/iZldLWm/pCsb0yKAIlQMu7s/rPyfbrik2HYANApflwWCIOxAEIQdCIKwA0EQdiAIG/zyW3NMsil+gY3ME/htHefk1jrW7U+u+09ve6SubVf6qepKl9imPHoi/dpL/7MrWe9YPnqnmx6JNnu3jvnRYUfP2LMDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBD8lHSVTv7mt7m1PZ+YlVx37rXXJuu7rvyXWlqqypwNn0/W333bS8l6x6OMo48W7NmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAiuZwdGEa5nB0DYgSgIOxAEYQeCIOxAEIQdCIKwA0FUDLuZzTSzTWa2y8weN7MV2fKbzeygmW3P/i5rfLsAalXNj1f0S7rB3beZ2URJW81sY1a71d1vaVx7AIpSzfzsvZJ6s/vHzWy3pBmNbgxAsU7pmN3MZkmaL2lztugaM3vMzNaY2eScdbrMrMfMevp0oq5mAdSu6rCb2RmS7pZ0nbsfk/RtSedImqfBPf/XhlvP3Ve7e6e7d7ZrbAEtA6hFVWE3s3YNBv1H7n6PJLn7IXc/6e4Dkr4raUHj2gRQr2rOxpuk2yXtdvevD1k+fcjTrpC0s/j2ABSlmrPxH5J0laQdZrY9W3aTpKVmNk+SS9on6XMN6RBAIao5G/+wpOGuj91QfDsAGoVv0AFBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Jo6pTNZvY/kvYPWXSWpOea1sCpadXeWrUvid5qVWRvf+jubx2u0NSwv2njZj3u3llaAwmt2lur9iXRW62a1Rsf44EgCDsQRNlhX13y9lNatbdW7Uuit1o1pbdSj9kBNE/Ze3YATULYgSBKCbuZLTKzJ83sKTO7sYwe8pjZPjPbkU1D3VNyL2vM7LCZ7RyybIqZbTSzPdntsHPsldRbS0zjnZhmvNT3ruzpz5t+zG5mbZJ+I+njkg5I2iJpqbvvamojOcxsn6ROdy/9Cxhm9hFJL0i6093Py5Z9VdJRd1+Z/UM52d2/1CK93SzphbKn8c5mK5o+dJpxSZdL+oxKfO8SfV2pJrxvZezZF0h6yt33uvurku6StKSEPlqeuz8k6egbFi+RtDa7v1aD/7M0XU5vLcHde919W3b/uKTXphkv9b1L9NUUZYR9hqSnhzw+oNaa790lPWBmW82sq+xmhjHN3Xuz+89KmlZmM8OoOI13M71hmvGWee9qmf68Xpyge7OL3P39khZL+kL2cbUl+eAxWCuNnVY1jXezDDPN+O+V+d7VOv15vcoI+0FJM4c8fke2rCW4+8Hs9rCke9V6U1Efem0G3ez2cMn9/F4rTeM93DTjaoH3rszpz8sI+xZJs83sXWZ2mqRPSVpfQh9vYmYTshMnMrMJki5V601FvV7Ssuz+Mkn3ldjL67TKNN5504yr5Peu9OnP3b3pf5Iu0+AZ+d9K+rsyesjp62xJv87+Hi+7N0nrNPixrk+D5zaulvQWSd2S9kh6UNKUFurtB5J2SHpMg8GaXlJvF2nwI/pjkrZnf5eV/d4l+mrK+8bXZYEgOEEHBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0H8Px6GUTt0IpTWAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Size of image\n",
        "X_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1FGBh6C0zAQ",
        "outputId": "90b6210e-46ad-495c-9ce6-0958e70db6e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The images are 28x28 pixel grey scale, and there are 60000 images/observations in this dataset.\n",
        "X_train.shape\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SjNQIAO09W2",
        "outputId": "2c7b56c4-6ef6-4af2-ce3e-80d0ed3ea266"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(60000,28,28,1)\n",
        "X_test = X_test.reshape(10000,28,28,1)\n"
      ],
      "metadata": {
        "id": "APqui4SY1lgE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#60000 images, 28x28x1\n",
        "X_train.shape "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6MfPBjv10Fn",
        "outputId": "34133eed-6bda-42fa-a446-11a71e275f65"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#label of the input - I have 10 labels here, from 0-9.\n",
        "y_train\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VuE481H16b2",
        "outputId": "cc09f13f-42bb-458b-e5fb-5b529a2fabcb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert the output into 0 and 1\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#One hot encoding on target column\n",
        "y_train=to_categorical(y_train)\n",
        "y_test=to_categorical(y_test)\n"
      ],
      "metadata": {
        "id": "BTSAr-M-2NvF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert data into 0 and 1\n",
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0zeGuaD2xSd",
        "outputId": "672dd709-3bbf-4f57-a649-8b68c6ee0fc6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#60000 tuples, and 10 columns - now data is categorical.\n",
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtVrdAOI21oF",
        "outputId": "bf4bb217-3df1-4575-fed2-2566adffd1f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.backend import softmax\n",
        "#CNN architecture\n",
        "#Create the model.\n",
        "model=Sequential()\n",
        "#Add the CNN layers.\n",
        "model.add(Conv2D(filters=64,kernel_size=3,activation='relu',input_shape=(28,28,1)))\n",
        "model.add(Conv2D(filters=32,kernel_size=3,activation='relu')) #Note that input shape is removed, as this is only necessary for the first layer.\n",
        "\n",
        "#FCN\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1000,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "8bAaL5Fq3KRd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the change in the shape and how many parameters are we learning?\n",
        "\n",
        "Shape - 28x28 = 26x26 in 1st layer, then 24x24 in next layer. Filter is 3x3.\n",
        "(input)-(filter-1)\n",
        "\n",
        "First layer\n",
        "28-(3-1) = 26, which is in the first layer, - 64 filters in layer one\n",
        "\n",
        "Second layer\n",
        "\n",
        "24*24*32\n",
        "\n",
        "Parameters\n",
        "((Filter) + Bias)*filters\n",
        "\n",
        "First layer\n",
        "((3*3)+1)*64 layers in first = 640 features in layer one\n",
        "\n",
        "Second layer\n",
        "\n",
        "((3*3*64)+1)*32 = 18464\n",
        "\n",
        "\n",
        "Flattened layer\n",
        "\n",
        "24*24*32 = 18432\n",
        "\n",
        "Dense (hidden) layer\n",
        "Bias is added here.\n",
        "\n",
        "18432*1000\n"
      ],
      "metadata": {
        "id": "ZtWa7gtP7jzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First convolutional layer is 26x26 - 64 filters - 640 parameters\n",
        "model.summary() #18432+1 = 18433*1000 = 18433000\n",
        "\n",
        "#1000*10 = 10010\n",
        "\n",
        "#Add total parameters = 640, 18464, 0, 18433000, 10010"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQTDrHDh7WP7",
        "outputId": "8c83c208-4e01-4915-bdc7-390cfd836a6b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 64)        640       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 32)        18464     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 18432)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              18433000  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                10010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,462,114\n",
            "Trainable params: 18,462,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e_1XEfxh_fss"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN architecture\n",
        "#Create the model.\n",
        "model=Sequential()\n",
        "#Add the CNN layers.\n",
        "model.add(Conv2D(filters=32,kernel_size=(5,5),activation='relu',input_shape=(28,28,1))) #You may not want to reduce size of image, use padding values.\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters=62,kernel_size=(5,5),activation='relu')) #Note that input shape is removed, as this is only necessary for the first layer.\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#FCN\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1000,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "MvhGV6F4_f-F"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW9sTUWA9BF8",
        "outputId": "58c27fe8-af24-47ae-997e-1065c833fb89"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 8, 62)          49662     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 4, 4, 62)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 992)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1000)              993000    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                10010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,053,504\n",
            "Trainable params: 1,053,504\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "69wCykJbBVu5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,\n",
        "          validation_data=(X_test,y_test),epochs=5)\n",
        "#If you do not pass a batch size, the automatic is 32.\n",
        "#60,000/32 = 1875 iterations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV-cm8B3BnAK",
        "outputId": "611b7e88-4ea6-4e83-f429-c67e62cd9585"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.2994 - accuracy: 0.9497 - val_loss: 0.0692 - val_accuracy: 0.9786\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 98s 52ms/step - loss: 0.0739 - accuracy: 0.9780 - val_loss: 0.0667 - val_accuracy: 0.9791\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 85s 45ms/step - loss: 0.0667 - accuracy: 0.9807 - val_loss: 0.0618 - val_accuracy: 0.9823\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 88s 47ms/step - loss: 0.0627 - accuracy: 0.9824 - val_loss: 0.0748 - val_accuracy: 0.9794\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 101s 54ms/step - loss: 0.0511 - accuracy: 0.9858 - val_loss: 0.1015 - val_accuracy: 0.9772\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6057c8d9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN-R5sP7D160",
        "outputId": "575adfd6-9143-4226-cc1e-49d45c70cf80"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}